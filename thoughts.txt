Most people I know in the data science industry -and elsewhere- either ignore LLMs altogether or sporadically use them as gadgets. 
I suspect various reasons, among them an aversion to changing habits and challenging new workflows.

To me, questions about the "meaning" or the "future" of AI for humanity are irrelevant at this point. 
Generative AI is a superb tool that is an EXCELLENT complement to the human brain (it is, after all, a mere extension of some of its most basic functions).
Mastering what I call the "generative dialogue" involves several important steps.

1. What generation is and is not

Generation probalistically completes the next step of a given task in a given context. 
Context comes from both the provider (pre-prompt) and the user (prompt, uploaded files).
A probabilistic model cannot in any circumstance come close to what we know as knowledge or, more importantly, judgement.
Steven Wolfram is quite good at explaining why associating procedural and generative AI in the future can be part of the solution.
In any case, even though it is an unpopular opinion in the well spread analytic philosophy tradition, I do not believe that any form of judgement
can ever be expected from a system, however complex, that has no biological component. Were it to change, however... Hard to say. 

2. Understanding both provider and user role in the dialogue

The provider (OpenAI, Google, Meta...) is responsible for the general design of the model and its main pre-prompts.
Provider orientations command the opportunity of using a model for a given task. 
Using gpt-4 to trick teachers into grading its essays is funny but useless. Using gpt-4 to ask existential question is plain stupidity.
Given the design and recent beta features, it appears clearly that gpt-4 is currently best suited for automation of text edition (draft an email
from notes, an executive summury, an add...) and, more importantly, programming (see python interpreter and file management plugins).
Interestingly, it is quite proficient at idea generation, which will be discussed later.

The user (you and me) must first understand the relevance of the model they intend to use depending on provider specifications.
With that information in mind, the user should swiftly reckon at which milestones in their workflow the model shall intervene.
Gpt-4 might not give the user up-to-date api specifications, however it's python interpreter can considerably reduce data preprocessing script design. 
The user must also be well aware of their own areas of expertise and limits. 
An international affairs specialist wanting to write a sentiment analysis script about South East Asia will will know precisely what to ask the generative model (assuming that he is also a programmer). 
However the lack of knowledge in the field of application of a programming project is a major barrier to the use of generative models. 
They will not help with right or wrong, they will not help with better understanding of a topic. 
For that reason I have come accross two kinds of inneficient users who fail to see the wonderful opportunities offered by generative model : 
users with a solid programming/ data science background but very limited other interests, who lack any creative impulse, 
and those with different expertise who are paralysed by their complete ignorence of programming and computer science in general. 
A proficient user will be a jack of all trades. 

3. In the dialogue their is only the user's intelligence is at play, or rather what can be communicated of that intelligence

4. Generative AI abstract a higher level language with no other libraries than the user's brain







